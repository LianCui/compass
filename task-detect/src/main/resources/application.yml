server:
  port: 7071

spring:
  application:
    name: "task-detect"
  profiles:
    active:
  jackson:
    time-zone: GMT+8
    date-format: yyyy-MM-dd HH:mm:ss
  datasource:
    url: jdbc:mysql://localhost:33066/compass?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai
    username: root
    password: root
    druid:
      initial-size: 5
      min-idle: 10
      max-active: 20
  redis:
    cluster:
      nodes: localhost:6379
      max-redirects: 3
    password:
    lettuce:
      pool:
        max-active: 32
        max-idle: 16
        min-idle: 8
  elasticsearch:
    nodes: localhost:19527
    username:
    password:

  kafka:
    bootstrap-servers: "localhost:9095"
    topics: "compass_test"
    consumer:
      group-id: "compass_test_22047328"
      auto-offset-reset: "earliest"
      max-poll-interval-ms: 300000
      security-protocol: "SASL_PLAINTEXT"
      sasl-mechanism: "SCRAM-SHA-512"
      sasl-jaas-config: "org.apache.kafka.common.security.scram.ScramLoginModule required username='hdop' password='v41ieoEFhnPajg5L';"

custom:
  schedulerType: ${SCHEDULER:dolphinscheduler}
  redis:
    logRecord: "{lua}:log:record"
    delayedQueue: "{lua}:delayed:task"
    processing: "{lua}:detected:processing"
  delayedTaskQueue:
    enable: true
    delayedSeconds: 10
    tryTimes: 5
  elasticsearch:
    yarn-app-index: "compass-yarn-app"
    spark-app-index: "compass-spark-app"
    job-index: "compass-job-analysis"
    app-index: "compass-task-app"
    job-instance-index: "compass-job-instance"

  detectionRule:
    # 运行耗时长配置，单位小时
    durationWarning: 2
    # 长期失败配置，单位天
    alwaysFailedWarning: 10

  sparkUiProxy:
    url: "http://%s:18018/history/%s"